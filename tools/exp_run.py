"""
Script for running 'learning assembly domain from demonstrations' experiments. Each
experiment run consists of the initial assembly request from the (simulated) user
and the ensuing series of interactions that differ based on the agent's belief states
and dialogue participants' choice of dialogue strategies.

Can be run in 'training mode' or 'test mode'. Different statistics are recorded
for each mode. For the former, we track the cumulative regret curves across the
series of interaction episodes. The latter mode is for evaluation; it disables
the agent's learning capability, fixing the agent's knowledge across the evaluation
suite, measuring the agent's answers and ground truths for the 'test problems'.
"""
import os
import re
import sys
sys.path.insert(
    0,
    os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
)
import uuid
import random
import logging
import warnings
warnings.filterwarnings("ignore")
from PIL import Image
from itertools import product, groupby
from collections import defaultdict

import hydra
import numpy as np
from omegaconf import OmegaConf
from torch.utils.tensorboard import SummaryWriter
from mlagents_envs.environment import UnityEnvironment
from mlagents_envs.side_channel.environment_parameters_channel import EnvironmentParametersChannel

from python.itl import ITLAgent
from tools.sim_user import SimulatedTeacher
from tools.message_side_channel import StringMsgChannel


logger = logging.getLogger(__name__)
TAB = "\t"

OmegaConf.register_new_resolver(
    "randid", lambda: str(uuid.uuid4())[:6]
)
@hydra.main(config_path="../python/itl/configs", config_name="config")
def main(cfg):
    print(OmegaConf.to_yaml(cfg, resolve=True))

    # Set seed
    random.seed(cfg.seed)
    np.random.seed(cfg.seed)
    # Note: Make sure to control the environment variable PYTHONHASHSEED
    # (**before** starting the script) for complete reproducibility!

    # Experiment tag
    exp_tag = "_".join([
        cfg.exp.task.split("_")[-1],
        cfg.exp.player_type,
        str(cfg.seed)
    ])

    # Path to save result metrics
    results_path = os.path.join(cfg.paths.outputs_dir, "results")
    os.makedirs(results_path, exist_ok=True)

    # Path to save agent models during & after training
    ckpt_path = os.path.join(cfg.paths.outputs_dir, "agent_model")
    os.makedirs(ckpt_path, exist_ok=True)

    # Tensorboard writer to log learning progress
    writer = SummaryWriter(f"{cfg.paths.outputs_dir}/tensorboard_logs")
    metrics = []

    # Set up student & teacher
    agent = ITLAgent(cfg)
    user = SimulatedTeacher(cfg)

    # Two types of task to teach/learn:
    #   "build_truck_supertype": Learn how to build instances of the broad truck
    #       supertype, where main learning targets are the types of constituent
    #       parts, valid assembly pairs, contact points and the general desired
    #       'assembly topology'
    #   "build_truck_subtype": Learn how to build fine-grained subtypes of trucks,
    #       where main learning targets are ontology rules (definitions and constraints)
    #       that need to be followed
    # In addition, "inject_color" is specified for the preparation step where
    # the agent is pre-trained with color concepts
    target_task = cfg.exp.task

    # Student/teacher-side string message communication side channels
    # (UUIDs generated by UUID4)
    agent_channel = StringMsgChannel("a1a6b269-0dd3-442c-99c6-9c735ebe43e1")
    user_channel = StringMsgChannel("da85d4e0-1b60-4c8a-877d-03af30c446f2")

    # This channel communicates environment parameters for random initializations
    env_par_channel = EnvironmentParametersChannel()

    # Start communication with Unity
    env = UnityEnvironment(
        # Uncomment next line when running with Unity linux build
        f"{cfg.paths.build_dir}/truck_domain.x86_64",
        side_channels=[agent_channel, user_channel, env_par_channel],
        timeout_wait=600, seed=cfg.seed
    )

    # Camera calibration as needed
    if cfg.vision.calibrate_camera:
        logger.info(f"Sys> Calibrating agent camera...")

        # Request images (#=24) containing a checkerboard pattern in the view,
        # used for camera calibration
        calib_images = []
        for i in range(24):
            # Request image and wait
            agent_channel.send_string("System", f"# Calibration image request: {i}", {})
            env.step()

            # Fetch image from response and append to list
            b_name, b_spec = list(env.behavior_specs.items())[0]
            assert b_name.startswith("StudentBehavior")
            dec_steps, _ = env.get_steps(b_name)
            vis_obs = (dec_steps[0].obs[0] * 255).astype(np.uint8).transpose(1,2,0)
            vis_obs = np.ascontiguousarray(vis_obs, dtype=np.uint8)
            calib_images.append(vis_obs)

        # Real-world 3d coordinates of grid points
        x_grid = [0.05 * (6-i) - 0.15 for i in range(7)]
        y_grid = [0.05 * i + 0.875 for i in range(6)]
        points_3d = [np.array([
            [x_val, y_val, 0] for y_val, x_val in product(y_grid, x_grid)   # Row-major
        ], dtype=np.float32)] * len(calib_images)

        # Camera intrinsics will be stored in vision module
        agent.vision.calibrate_camera(calib_images, points_3d)
        
    else:
        # Skipping camera calibration step by using parameters obtained in advance...
        cam_K = np.array([
            [521.756, 0, 399.149],
            [0, 521.345, 304.926],
            [0, 0, 1]
        ])
        distortion_coeffs = np.array([
            [0.00223, 0.00731, 0.00180, -0.00035, -0.01217]
        ])
        agent.vision.camera_intrinsics = (cam_K, distortion_coeffs)

    # Send end-of-request signal so that agent's default position is ensured and
    # chessboard pattern object is deactivated
    agent_channel.send_string("System", "# Calibration image request: 24", {})

    # Send a request for orderings of part & color subtypes as specified in Unity
    # environment scene (stored in TeacherAgent instance), so that we can convert
    # randomly sampled initialization configs to environment in corresponding numbers
    user_channel.send_string("System", "# Subtype orderings request", {})

    env.step()

    # Extract subtype ordering info from response message and store
    incoming_msgs = user_channel.incoming_message_buffer
    all_subtypes = {}
    while len(incoming_msgs) > 0:
        spk, utterance, _ = incoming_msgs.pop(0)
        if spk == "System" and utterance.startswith("# Subtype orderings response: "):
            per_supertype = utterance.replace("# Subtype orderings response: ", "")
            per_supertype = per_supertype.split(" // ")

            for info_string in per_supertype:
                supertype, subtypes = info_string.split(" - ")
                all_subtypes[supertype] = subtypes.split(", ")
        else:
            raise ValueError        # Shouldn't happen

    for ep_i in range(cfg.exp.num_episodes+1):
        logger.info(f"Sys> Episode {ep_i})")

        # Obtain random initialization of each episode
        sampled_inits = user.setup_episode(target_task, all_subtypes)

        # Send the randomly initialized parameters to Unity
        for field, value in sampled_inits.items():
            if "viol" in field: continue
            env_par_channel.set_float_parameter(field, value)

        if target_task == "build_truck_supertype":
            # Fix the pool of possible subtypes into only the sampled ones for
            # the remaining episodes (except color attributes)
            occurring_subtypes = {
                (f_spl[0], value) for field, value in sampled_inits.items()
                if (f_spl := field.split("/"))[2] == "type"
            }
            occurring_subtypes = groupby(sorted(occurring_subtypes), lambda x: x[0])
            for supertype, sampled_subtypes in occurring_subtypes:
                # Replace unoccurring subtypes with None rather than deleting
                # in order to preserve indices
                sampled_subtypes = [i for _, i in sampled_subtypes]
                all_subtypes[supertype] = [
                    subtype if i in sampled_subtypes else None
                    for i, subtype in enumerate(all_subtypes[supertype])
                ]

        # Request sending ground-truth mask info to teacher at the beginning
        agent_channel.send_string("System", "# GT mask request: *", {})

        # Send teacher's episode-initial output---thus user's episode-initial input
        opening_output = user.initiate_dialogue()
        for usr_in in opening_output:
            user_channel.send_string(
                "Teacher", usr_in["utterance"], usr_in["pointing"]
            )
            logger.info(f"T> {TAB}{usr_in['utterance']}")

        # Let the settings take effect and begin the episode
        env.reset()
        new_env = True

        while True:
            # Keep running until either student or teacher terminates episode
            terminate = False

            for b_name, b_spec in env.behavior_specs.items():
                # Decision steps (agents requiring decisions) and terminal steps
                # (agents terminated)
                dec_steps, _ = env.get_steps(b_name)

                # Handle each decision request
                for di in dec_steps:
                    dec_step = dec_steps[di]

                    # Handle student's decision request
                    if b_name.startswith("StudentBehavior"):
                        # Dictionary containing input for next agent loop
                        agent_loop_input = {
                            "v_usr_in": None,
                            "l_usr_in": [],
                            "speaker": [],
                            "pointing": [],
                            "new_env": new_env
                        }

                        # Obtain agent's visual observation from camera sensor
                        vis_obs = dec_step.obs[0]
                        vis_obs = (vis_obs.transpose(1,2,0) * 255).astype(np.uint8)
                        i_h, i_w, _ = vis_obs.shape
                        agent_loop_input["v_usr_in"] = Image.fromarray(vis_obs, mode="RGB")

                        # Read messages stored in string message channel buffer
                        incoming_msgs = agent_channel.incoming_message_buffer

                        sys_msg_only = True
                        while len(incoming_msgs) > 0:
                            spk, utterance, dem_refs = incoming_msgs.pop(0)
                            # 1D to 2D according to visual scene dimension
                            dem_refs = {
                                crange: ref if isinstance(ref, str) else 
                                    np.array(ref).reshape(i_h, i_w)
                                for crange, ref in dem_refs.items()
                            }
                            if spk == "System" and utterance.startswith("# GT mask response: "):
                                # As it stands, code enters here only at the beginning of each
                                # episode, so can refresh student state with new_env of True
                                # and empty user input
                                agent.loop(new_env=True)
                                agent_loop_input["new_env"] = False
                                # Run visual scene prediction with provided ground-truth masks
                                agent.vision.predict(
                                    agent_loop_input["v_usr_in"], agent.lt_mem.exemplars,
                                    masks={
                                        f"o{i}": v for i, v in enumerate(dem_refs.values())
                                        if v.sum() > 100        # Remove small/null masks
                                    }
                                )
                                visual_evidence = agent.lt_mem.kb.visual_evidence_from_scene(
                                    agent.vision.scene
                                )
                                agent.symbolic.sensemake_vis(None, visual_evidence)
                                # Record instance names used in the environment side associated
                                # with each object
                                aliases = user.current_episode_record["assembly_state"]["aliases"]
                                    # Provide teacher with access to the object correspondence as well
                                for oi, crange in enumerate(dem_refs):
                                    name_with_type = utterance[crange[0]:crange[1]].split("/")
                                    env_handle, type_code = name_with_type
                                    agent.vision.scene[f"o{oi}"].update({
                                        "env_handle": env_handle, "type_code": type_code
                                    })
                                    aliases[f"o{oi}"] = env_handle
                                # Log mean F1 score across part types for non-initial episodes
                                if ep_i > 0:
                                    # Compute F1 scores for all categories known to agent with
                                    # few-shot binary classifiers available, then log average
                                    groundings = []
                                    color_concs = {
                                        agent.lt_mem.lexicon.s2d[("a", col)][0][1]: col
                                        for col in ["red", "green", "blue", "gold", "white"]
                                    }
                                    if cfg.exp.task == "inject_color":
                                        # Tracking color classification accuracy scores
                                        current_sample = user.current_episode_record["sampled_parts"]
                                        get_label = lambda c: agent.lt_mem.lexicon.d2s[("pcls", c)][0][1]
                                        for obj in agent.vision.scene.values():
                                            scores = obj["pred_cls"].copy()
                                            noncolor_inds = ~np.isin(np.arange(len(scores)), list(color_concs))
                                            scores[noncolor_inds] = np.nan
                                            ans_conc = np.nanargmax(scores)
                                            ans_prob = scores[ans_conc]
                                            ans_label = color_concs[ans_conc]
                                            inst = re.findall(r"([td])_(.*)_(\d+)$", obj["env_handle"])[0]
                                            inst = (inst[1], (inst[0], int(inst[2])))
                                            gt_label = current_sample[inst].get("color")
                                            if gt_label is not None:
                                                # Only tracking colorable parts
                                                groundings.append((gt_label, ans_label))
                                    else:
                                        # Tracking part type classification accuracy scores
                                        get_label = lambda c: agent.lt_mem.lexicon.codesheet[c] \
                                            if cfg.exp.player_type in ["bool", "demo"] \
                                            else agent.lt_mem.lexicon.d2s[("pcls", c)][0][1]
                                        for obj in agent.vision.scene.values():
                                            scores = obj["pred_cls"].copy()
                                            color_inds = np.isin(np.arange(len(scores)), list(color_concs))
                                            scores[color_inds] = np.nan
                                            ans_conc = np.nanargmax(scores)
                                            ans_prob = scores[ans_conc]
                                            ans_label = get_label(ans_conc) if ans_prob >= 0.35 else None
                                            if cfg.exp.task == "build_truck_supertype" and \
                                                cfg.exp.player_type in ["label", "full"]:
                                                # Supertype as ground-truth label for base-difficulty task
                                                # with languageful agents
                                                gt_label = re.findall(r"t_(.*)_\d+$", obj["env_handle"])[0]
                                            else:
                                                # Subtype as ground-truth label otherwise
                                                gt_label = obj["type_code"]
                                            groundings.append((gt_label, ans_label))
                                    stats = defaultdict(lambda: { "tp": 0, "fp": 0, "fn": 0 })
                                    for gt, ans in groundings:
                                        if gt == ans:
                                            stats[gt]["tp"] += 1        # True positive for gt/ans
                                        else:
                                            stats[gt]["fn"] += 1        # False negative for gt
                                            stats[ans]["fp"] += 1       # False positive for ans
                                    f1_scores = {}
                                    for c in agent.lt_mem.exemplars.binary_classifiers_2d["pcls"]:
                                        # Looping only for concepts whose binary classifier exists
                                        label = get_label(c)
                                        tp = stats[label]["tp"]
                                        fp = stats[label]["fp"]
                                        fn = stats[label]["fn"]
                                        if tp == 0:
                                            # Edge cases needing careful handling
                                            if fp == 0 and fn == 0:
                                                # No concept instance, successfully avoided false positives.
                                                # Consider as 100% success for the concept.
                                                f1 = 1.0
                                            else:
                                                # If FP > 0, precision is zero; if FN > 0, recall is zero.
                                                # Consider as 100% failure for the concept.
                                                f1 = 0.0
                                        else:
                                            # General cases
                                            precision = tp / (tp + fp); recall = tp / (tp + fn)
                                            f1 = 2 * precision * recall / (precision + recall)
                                        f1_scores[c] = f1
                            else:
                                # General case where message from Teacher or Student-side
                                # action effect feedback from Unity environment has arrived
                                agent_loop_input["l_usr_in"].append(utterance)
                                agent_loop_input["speaker"].append(spk)
                                agent_loop_input["pointing"].append(dem_refs)
                                sys_msg_only = False

                        # ITL agent loop: process input and generate output (action)
                        act_out = [] if sys_msg_only else agent.loop(**agent_loop_input)

                        if len(act_out) > 0:
                            # Process action output accordingly by setting Unity MLAgent
                            # actions and sending string messages via side channel
                            action = b_spec.action_spec.empty_action(1)
                            for act_type, act_params in act_out:
                                if act_type is None: continue       # Nothing to do

                                if act_type == "generate":
                                    action.discrete[0][0] = 1       # 'Utter' action
                                    utterance = act_params[0]
                                    dem_refs = {
                                        crange: (
                                            ref.reshape(-1).tolist() if as_mask else ref,
                                            as_mask
                                        )
                                        for crange, (ref, as_mask) in act_params[1].items()
                                    }
                                    agent_channel.send_string(
                                        "Student", utterance, dem_refs
                                    )
                                    if not utterance.startswith("#"):
                                        logger.info(f"L> {TAB}{utterance}")
                                else:
                                    # Physical action as planned and selected; set discrete
                                    # action type and send string parameters via channel
                                    action.discrete[0][1] = \
                                        agent.lt_mem.lexicon.s2d[("va", act_type)][0][1]
                                    str_params = ", ".join(act_params["parameters"])
                                    full_spec = f"# Action parameters: {str_params}"
                                    dem_refs = {
                                        crange: mask.reshape(-1).tolist()
                                        for crange, mask in act_params["pointing"].items()
                                    }
                                    agent_channel.send_string("System", full_spec, dem_refs)

                            # Finally apply actions
                            env.set_action_for_agent(b_name, dec_step.agent_id, action)
                        else:
                            # Terminate only if no act_out given despite non-system messages
                            # were processed
                            if not sys_msg_only: terminate = True

                    # Handle teacher's decision request
                    if b_name.startswith("TeacherBehavior"):
                        agent_reactions = []

                        # Read messages stored in string message channel buffer
                        incoming_msgs = user_channel.incoming_message_buffer

                        while len(incoming_msgs) > 0:
                            spk, utterance, dem_refs = incoming_msgs.pop(0)
                            # 1D to 2D according to visual scene dimension as needed
                            dem_refs = {
                                crange: ref if isinstance(ref, str) else 
                                    np.array(ref).reshape(i_h, i_w)
                                for crange, ref in dem_refs.items()
                            }
                            if spk == "System" and utterance.startswith("# GT mask response: "):
                                # Retrieve and store requested GT mask info in teacher
                                user.current_gt_masks = {
                                    utterance[crange[0]:crange[1]]: msk
                                    for crange, msk in dem_refs.items()
                                }
                            else:
                                agent_reactions.append((utterance, dem_refs))

                        # Simulated teacher (user) response
                        user_response = user.react(agent_reactions)

                        if len(user_response) > 0:
                            action = b_spec.action_spec.empty_action(1)
                            for act_data in user_response:
                                act_type, act_params = act_data
                                if act_type is None: continue       # Nothing to do

                                if act_type == "generate":
                                    # 'Utter' action
                                    action.discrete[0][0] = 1
                                    utterance = act_params["utterance"]
                                    dem_refs = act_params["pointing"]
                                    user_channel.send_string("Teacher", utterance, dem_refs)
                                    if not utterance.startswith("#"):
                                        logger.info(f"T> {TAB}{utterance}")
                                    if utterance.startswith("I will demonstrate how to"):
                                        # Purely for logging purpose
                                        logger.info(f"T> {TAB}[Demonstrating a full action sequence...]")
                                else:
                                    # Physical actions for demonstration; set discrete action
                                    # type and send string parameters via channel
                                    action.discrete[0][1] = \
                                        agent.lt_mem.lexicon.s2d[("va", act_type)][0][1]
                                    str_params = ", ".join(
                                        str(prm) for prm in act_params["parameters"]
                                    )
                                    full_spec = f"# Action parameters: {str_params}"
                                    user_channel.send_string("System", full_spec, {})

                            # Finally apply actions
                            env.set_action_for_agent(b_name, dec_step.agent_id, action)
                        else:
                            terminate = True

            if terminate:
                # End of episode, push record to history and break
                user.episode_records.append(user.current_episode_record)

                # Hard resetting existing environment parameter values with -1;
                # any fields not overwritten in the next initialization step
                # will be ignored
                for field, value in sampled_inits.items():
                    if "viol" in field: continue
                    env_par_channel.set_float_parameter(field, -1)

                break
            else:
                new_env = False
                env.step()

        # Collect metrics for the episode (except for the very first one with
        # full demo)
        if ep_i > 0:
            ep_metric = {}
            for metric, val in user.current_episode_record["metrics"].items():
                ep_metric[metric] = val
            for metric, val in agent.planner.execution_state.get("metrics", {}).items():
                ep_metric[metric] = val
            ep_metric["episode_length"] = len(
                agent.planner.execution_state.get("action_history", [])
            )
            ep_metric["mean_f1"] = sum(f1_scores.values()) / len(f1_scores)
            metrics.append(ep_metric)
            # Log progress to tensorboard
            for metric, val in ep_metric.items():
                writer.add_scalar(metric, val, global_step=ep_i)

    # Close Unity environment & tensorboard writer
    env.close()
    writer.close()

    if cfg.exp.task == "inject_color":
        # Just save the model
        agent.save_model(f"{cfg.paths.outputs_dir}/agent_model/color_pretrained.ckpt")
    else:
        # Save evaluation metric curves to output dir
        out_csv_fname = f"{exp_tag}.csv"

        with open(os.path.join(results_path, out_csv_fname), "w") as out_csv:
            metric_types = [
                "num_search_failure", "num_invalid_pickup",
                "num_invalid_join", "num_planning_forfeiture",
                "episode_discarded", "num_planning_attempts",
                "num_collision_queries", "episode_length", "mean_f1"
            ]
            out_csv.write("episode," + ",".join(metric_types) + "\n")
            for ep_i, ep_metric in enumerate(metrics):
                metric_values = [str(ep_metric[m_type]) for m_type in metric_types]
                metric_values = ",".join(metric_values)
                out_csv.write(f"{ep_i+1},{metric_values}\n")

if __name__ == "__main__":
    main()
