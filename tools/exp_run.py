"""
Script for running 'learning assembly domain from demonstrations' experiments. Each
experiment run consists of the initial assembly request from the (simulated) user
and the ensuing series of interactions that differ based on the agent's belief states
and dialogue participants' choice of dialogue strategies.

Can be run in 'training mode' or 'test mode'. Different statistics are recorded
for each mode. For the former, we track the cumulative regret curves across the
series of interaction episodes. The latter mode is for evaluation; it disables
the agent's learning capability, fixing the agent's knowledge across the evaluation
suite, measuring the agent's answers and ground truths for the 'test problems'.
"""
import os
import sys
sys.path.insert(
    0,
    os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
)
import uuid
import random
import logging
import warnings
warnings.filterwarnings("ignore")
from PIL import Image
from collections import defaultdict
from itertools import product, groupby

import hydra
import numpy as np
from omegaconf import OmegaConf
from torch.utils.tensorboard import SummaryWriter
from mlagents_envs.environment import UnityEnvironment
from mlagents_envs.side_channel.environment_parameters_channel import EnvironmentParametersChannel

from python.itl import ITLAgent
from tools.sim_user import SimulatedTeacher
from tools.message_side_channel import StringMsgChannel


logger = logging.getLogger(__name__)
TAB = "\t"

OmegaConf.register_new_resolver(
    "randid", lambda: str(uuid.uuid4())[:6]
)
@hydra.main(config_path="../python/itl/configs", config_name="config")
def main(cfg):
    print(OmegaConf.to_yaml(cfg, resolve=True))

    # Set seed
    random.seed(cfg.seed)
    np.random.seed(cfg.seed)

    # Experiment tag
    exp_tag = "_".join([
        cfg.exp.strat_feedback,
        cfg.agent.strat_generic,
        cfg.agent.strat_assent,
        str(cfg.seed)
    ])

    # Path to save result metrics
    results_path = os.path.join(cfg.paths.outputs_dir, "results")
    os.makedirs(results_path, exist_ok=True)

    # Path to save agent models during & after training
    if not cfg.agent.test_mode:
        ckpt_path = os.path.join(cfg.paths.outputs_dir, "agent_model")
        os.makedirs(ckpt_path, exist_ok=True)

    # Tensorboard writer to log learning progress
    writer = SummaryWriter(f"{cfg.paths.outputs_dir}/tensorboard_logs")
    mistakes = defaultdict(lambda: [(0,0)])         # Accumulating regrets

    # Set up student & teacher
    student = ITLAgent(cfg)
    teacher = SimulatedTeacher(cfg)

    # Two types of task to teach/learn:
    #   "build_truck_supertype": Learn how to build instances of the broad truck
    #       supertype, where main learning targets are the types of constituent
    #       parts, valid assembly pairs, contact points and the general desired
    #       'assembly topology'
    #   "build_truck_subtype": Learn how to build fine-grained subtypes of trucks,
    #       where main learning targets are ontology rules (definitions and constraints)
    #       that need to be followed
    target_task = cfg.exp.task

    # Student/teacher-side string message communication side channels
    # (UUIDs generated by UUID4)
    student_channel = StringMsgChannel("a1a6b269-0dd3-442c-99c6-9c735ebe43e1")
    teacher_channel = StringMsgChannel("da85d4e0-1b60-4c8a-877d-03af30c446f2")

    # This channel communicates environment parameters for random initializations
    env_par_channel = EnvironmentParametersChannel()

    # Start communication with Unity
    env = UnityEnvironment(
        # Uncomment next line when running with Unity linux build
        # f"{cfg.paths.build_dir}/truck_domain.x86_64",
        side_channels=[student_channel, teacher_channel, env_par_channel],
        timeout_wait=600, seed=cfg.seed
    )

    # Camera calibration as needed
    if cfg.vision.calibrate_camera:
        logger.info(f"Sys> Calibrating agent camera...")

        # Request images (#=24) containing a checkerboard pattern in the view,
        # used for camera calibration
        calib_images = []
        for i in range(24):
            # Request image and wait
            student_channel.send_string("System", f"# Calibration image request: {i}", {})
            env.step()

            # Fetch image from response and append to list
            b_name, b_spec = list(env.behavior_specs.items())[0]
            assert b_name.startswith("StudentBehavior")
            dec_steps, _ = env.get_steps(b_name)
            vis_obs = (dec_steps[0].obs[0] * 255).astype(np.uint8).transpose(1,2,0)
            vis_obs = np.ascontiguousarray(vis_obs, dtype=np.uint8)
            calib_images.append(vis_obs)

        # Real-world 3d coordinates of grid points
        x_grid = [0.05 * (6-i) - 0.15 for i in range(7)]
        y_grid = [0.05 * i + 0.875 for i in range(6)]
        points_3d = [np.array([
            [x_val, y_val, 0] for y_val, x_val in product(y_grid, x_grid)   # Row-major
        ], dtype=np.float32)] * len(calib_images)

        # Camera intrinsics will be stored in vision module
        student.vision.calibrate_camera(calib_images, points_3d)
        
    else:
        # Skipping camera calibration step by using parameters obtained in advance...
        cam_K = np.array([
            [521.756, 0, 399.149],
            [0, 521.345, 304.926],
            [0, 0, 1]
        ])
        distortion_coeffs = np.array([
            [0.00223, 0.00731, 0.00180, -0.00035, -0.01217]
        ])
        student.vision.camera_intrinsics = (cam_K, distortion_coeffs)

    # Send end-of-request signal so that agent's default position is ensured and
    # chessboard pattern object is deactivated
    student_channel.send_string("System", "# Calibration image request: 24", {})

    # Send a request for orderings of part & color subtypes as specified in Unity
    # environment scene (stored in TeacherAgent instance), so that we can convert
    # randomly sampled initialization configs to environment in corresponding numbers
    teacher_channel.send_string("System", "# Subtype orderings request", {})

    env.step()

    # Extract subtype ordering info from response message and store
    incoming_msgs = teacher_channel.incoming_message_buffer
    all_subtypes = {}
    while len(incoming_msgs) > 0:
        spk, utterance, _ = incoming_msgs.pop(0)
        if spk == "System" and utterance.startswith("# Subtype orderings response: "):
            per_supertype = utterance.replace("# Subtype orderings response: ", "")
            per_supertype = per_supertype.split(" // ")

            for info_string in per_supertype:
                supertype, subtypes = info_string.split(" - ")
                all_subtypes[supertype] = subtypes.split(", ")
        else:
            raise ValueError        # Shouldn't happen

    for i in range(cfg.exp.num_episodes):
        logger.info(f"Sys> Episode {i+1})")

        # Obtain random initialization of each episode
        sampled_inits = teacher.setup_episode(target_task, all_subtypes)

        # Send randomly initialized parameters to Unity
        for field, value in sampled_inits.items():
            env_par_channel.set_float_parameter(field, value)

        if target_task == "build_truck_supertype":
            # Fix the pool of possible subtypes into only the sampled ones for
            # the remaining episodes (except color attributes)
            occurring_subtypes = {
                (f_spl[0], value) for field, value in sampled_inits.items()
                if (f_spl := field.split("/"))[1] == "type"
            }
            occurring_subtypes = groupby(sorted(occurring_subtypes), lambda x: x[0])
            for supertype, sampled_subtypes in occurring_subtypes:
                # Replace unoccurring subtypes with None rather than deleting
                # in order to preserve indices
                sampled_subtypes = [i for _, i in sampled_subtypes]
                all_subtypes[supertype] = [
                    subtype if i in sampled_subtypes else None
                    for i, subtype in enumerate(all_subtypes[supertype])
                ]

        # Request sending ground-truth mask info to teacher at the beginning
        student_channel.send_string("System", "# GT mask request: *", {})

        # Send teacher's episode-initial output---thus user's episode-initial input
        opening_output = teacher.initiate_dialogue()
        teacher_channel.send_string(
            "Teacher", opening_output[0]["utterance"], opening_output[0]["pointing"]
        )
        logger.info(f"T> {TAB}{opening_output[0]['utterance']}")

        # Let the settings take effect and begin the episode
        env.reset()
        new_env = True

        while True:
            # Keep running until either student or teacher terminates episode
            terminate = False

            for b_name, b_spec in env.behavior_specs.items():
                # Decision steps (agents requiring decisions) and terminal steps
                # (agents terminated)
                dec_steps, _ = env.get_steps(b_name)

                # Handle each decision request
                for di in dec_steps:
                    dec_step = dec_steps[di]

                    # Handle student's decision request
                    if b_name.startswith("StudentBehavior"):
                        # Dictionary containing input for next agent loop
                        agent_loop_input = {
                            "v_usr_in": None,
                            "l_usr_in": [],
                            "speaker": [],
                            "pointing": [],
                            "new_env": new_env
                        }

                        # Obtain agent's visual observation from camera sensor
                        vis_obs = dec_step.obs[0]
                        vis_obs = (vis_obs.transpose(1,2,0) * 255).astype(np.uint8)
                        i_h, i_w, _ = vis_obs.shape
                        agent_loop_input["v_usr_in"] = Image.fromarray(vis_obs, mode="RGB")

                        # Read messages stored in string message channel buffer
                        incoming_msgs = student_channel.incoming_message_buffer

                        sys_msg_only = True
                        while len(incoming_msgs) > 0:
                            spk, utterance, dem_refs = incoming_msgs.pop(0)
                            # 1D to 2D according to visual scene dimension
                            dem_refs = {
                                crange: np.array(mask).reshape(i_h, i_w)
                                for crange, mask in dem_refs.items()
                            }
                            if spk == "System" and utterance.startswith("# GT mask response: "):
                                # As it stands, code enters here only at the beginning of each
                                # episode, so can refresh student state with new_env of True
                                # and empty user input
                                student.loop(new_env=True)
                                agent_loop_input["new_env"] = False
                                # Run visual scene prediction with provided ground-truth masks
                                student.vision.predict(
                                    agent_loop_input["v_usr_in"], student.lt_mem.exemplars,
                                    masks={
                                        f"o{i}": v for i, v in enumerate(dem_refs.values())
                                        if v.sum() > 100        # Remove small/null masks
                                    }
                                )
                                # Record instance names used in the environment side associated
                                # with each object
                                for i, crange in enumerate(dem_refs):
                                    env_name = utterance[crange[0]:crange[1]]
                                    student.vision.scene[f"o{i}"]["env_name"] = env_name
                            else:
                                # General case where message from Teacher or Student-side
                                # action effect feedback from Unity environment has arrived
                                agent_loop_input["l_usr_in"].append(utterance)
                                agent_loop_input["speaker"].append(spk)
                                agent_loop_input["pointing"].append(dem_refs)
                                sys_msg_only = False

                        # ITL agent loop: process input and generate output (action)
                        act_out = [] if sys_msg_only else student.loop(**agent_loop_input)

                        if len(act_out) > 0:
                            # Process action output accordingly by setting Unity MLAgent
                            # actions and sending string messages via side channel
                            action = b_spec.action_spec.empty_action(1)
                            for act_type, act_params in act_out:
                                if act_type is None: continue       # Nothing to do

                                if act_type == "generate":
                                    action.discrete[0][0] = 1       # 'Utter' action
                                    utterance = act_params[0]
                                    dem_refs = {
                                        crange: mask.reshape(-1).tolist()
                                        for crange, mask in act_params[1].items()
                                    }
                                    student_channel.send_string(
                                        "Student", utterance, dem_refs
                                    )
                                    if not utterance.startswith("#"):
                                        logger.info(f"L> {TAB}{utterance}")
                                else:
                                    # Physical action as planned and selected; set discrete
                                    # action type and send string parameters via channel
                                    action.discrete[0][1] = \
                                        student.lt_mem.lexicon.s2d[("va", act_type)][0][1]
                                    str_params = ", ".join(act_params["parameters"])
                                    full_spec = f"# Action parameters: {str_params}"
                                    dem_refs = {
                                        crange: mask.reshape(-1).tolist()
                                        for crange, mask in act_params["pointing"].items()
                                    }
                                    student_channel.send_string("System", full_spec, dem_refs)

                            # Finally apply actions
                            env.set_action_for_agent(b_name, dec_step.agent_id, action)
                        else:
                            # Terminate only if no act_out given despite non-system messages
                            # were processed
                            if not sys_msg_only: terminate = True

                    # Handle teacher's decision request
                    if b_name.startswith("TeacherBehavior"):
                        agent_reactions = []

                        # Read messages stored in string message channel buffer
                        incoming_msgs = teacher_channel.incoming_message_buffer

                        while len(incoming_msgs) > 0:
                            spk, utterance, dem_refs = incoming_msgs.pop(0)
                            # 1D to 2D according to visual scene dimension
                            dem_refs = {
                                crange: np.array(mask).reshape(i_h, i_w)
                                for crange, mask in dem_refs.items()
                            }
                            if spk == "System" and utterance.startswith("# GT mask response: "):
                                # Retrieve and store requested GT mask info in teacher
                                teacher.current_gt_masks = {
                                    utterance[crange[0]:crange[1]]: msk
                                    for crange, msk in dem_refs.items()
                                }
                            else:
                                agent_reactions.append((utterance, dem_refs))

                        # Simulated teacher (user) response
                        user_response = teacher.react(agent_reactions)

                        if len(user_response) > 0:
                            action = b_spec.action_spec.empty_action(1)
                            for act_data in user_response:
                                act_type, act_params = act_data
                                if act_type is None: continue       # Nothing to do

                                if act_type == "generate":
                                    # 'Utter' action
                                    action.discrete[0][0] = 1
                                    utterance = act_params["utterance"]
                                    dem_refs = act_params["pointing"]
                                    teacher_channel.send_string("Teacher", utterance, dem_refs)
                                    if not utterance.startswith("#"):
                                        logger.info(f"T> {TAB}{utterance}")
                                    if utterance.startswith("I will demonstrate how to"):
                                        # Purely for logging purpose
                                        logger.info(f"T> {TAB}[Demonstrating a full action sequence...]")
                                else:
                                    # Physical actions for demonstration; set discrete action
                                    # type and send string parameters via channel
                                    action.discrete[0][1] = \
                                        student.lt_mem.lexicon.s2d[("va", act_type)][0][1]
                                    str_params = ", ".join(act_params["parameters"])
                                    full_spec = f"# Action parameters: {str_params}"
                                    teacher_channel.send_string("System", full_spec, {})

                            # Finally apply actions
                            env.set_action_for_agent(b_name, dec_step.agent_id, action)
                        else:
                            terminate = True

            if terminate:
                # End of episode, push record to history and break
                teacher.episode_records.append(teacher.current_episode_record)
                break
            else:
                new_env = False
                env.step()

        for gt_conc, ep_log in teacher.current_episode_record.items():
            ans_conc = ep_log["answer"]

            # Update metrics
            regrets_conc, total_conc = mistakes[gt_conc][-1]
            regrets_all, total_all = mistakes["__all__"][-1]

            new_regrets_conc = regrets_conc+1 if gt_conc != ans_conc else regrets_conc
            new_total_conc = total_conc+1
            new_regrets_all = regrets_all+1 if gt_conc != ans_conc else regrets_all
            new_total_all = total_all+1

            # Log progress to tensorboard
            writer.add_scalar(
                f"Cumul. regret: {gt_conc}", new_regrets_conc, global_step=new_total_conc
            )
            writer.add_scalar(
                f"Cumul. regret: *All concepts*", new_regrets_all, global_step=new_total_all
            )
            mistakes[gt_conc].append((new_regrets_conc, new_total_conc))
            mistakes["__all__"].append((new_regrets_all, new_total_all))

        # If not test mode (i.e., training mode), save current agent model checkpoint
        # to output dir every 25 episodes
        if not cfg.agent.test_mode and (i+1) % cfg.exp.checkpoint_interval == 0:
            student.save_model(f"{ckpt_path}/{exp_tag}_{i+1}.ckpt")

    # Close Unity environment & tensorboard writer
    env.close()
    writer.close()

    if cfg.agent.test_mode:
        # If test mode, save exam records to output dir for later summary
        out_csv_fname = cfg.agent.model_path.split("/")[-1].replace(".ckpt",".csv")
        out_csv_fname = f"outputs_{out_csv_fname}"

        with open(os.path.join(results_path, out_csv_fname), "w") as out_csv:
            out_csv.write("episode,ground_truth,answer\n")

            for i, record in enumerate(teacher.episode_records):
                for gt_conc, ep_log in record.items():
                    ans_conc = ep_log["answer"]
                    out_csv.write(f"{i+1},{gt_conc},{ans_conc}\n")

    else:
        # Otherwise (i.e., learning enabled), save cumulative regret curves to output dir
        out_csv_fname = f"cumulReg_{exp_tag}.csv"

        with open(os.path.join(results_path, out_csv_fname), "w") as out_csv:
            out_csv.write("episode,cumulative_regret,reason_type\n")

            training_log = zip(mistakes["__all__"], [{}] + teacher.episode_records)
            for (regrets, total), ep_rec in training_log:
                ep_log = list(ep_rec.values())[0] if len(ep_rec) > 0 else {}
                if "reason" in ep_log:
                    reason_type = ep_log["reason"]
                else:
                    reason_type = "na"

                out_csv.write(f"{total},{regrets},{reason_type}\n")


if __name__ == "__main__":
    main()
